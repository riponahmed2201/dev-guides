# Database Scaling Techniques (ডিপ ডাইভ)

সিস্টেমের ইউজার এবং ট্রাফিক বাড়ার সাথে সাথে ডাটাবেসের ওপর চাপ বাড়তে থাকে। এই চাপ সামলানোর জন্য বিভিন্ন স্কেলিং টেকনিক ব্যবহার করা হয়। নিচে সেরা ১৫টি টেকনিক এবং সেগুলোর বিস্তারিত আলোচনা করা হলো।

---

## ১. টপ ১৫ ডাটাবেস স্কেলিং টেকনিক

১. **Indexing:** দ্রুত ডেটা খুঁজে পাওয়ার জন্য।
২. **Database Replication:** ডেটার কপি অন্য সার্ভারে রাখা।
৩. **Vertical Scaling:** সার্ভারের ক্ষমতা বাড়ানো।
৪. **Horizontal Scaling (Sharding):** ডেটা ভাগ করে অন্য সার্ভারে রাখা।
৫. **Database Partitioning:** বড় টেবিলকে ছোট ছোট টুকুরা করা।
৬. **Caching:** বারবার ব্যবহৃত ডেটা মেমরিতে রাখা।
৭. **Read/Write Splitting:** রিড এবং রাইট আলাদা সার্ভারে পাঠানো।
৮. **Denormalization:** জয়েন কমাতে ডেটা ডুপ্লিকেট করা।
৯. **Connection Pooling:** ডাটাবেস কানেকশন রিইউজ করা।
১০. **Query Optimization:** কুয়েরি লজিক উন্নত করা।
১১. **Database Clustering:** একাধিক সার্ভারকে একটি গ্রুপ হিসেবে ব্যবহার।
১২. **Data Compression:** স্টোরেজ এবং নেটওয়ার্ক ব্যান্ডউইথ বাঁচাতে।
১৩. **Change Data Capture (CDC):** রিয়েল-টাইম ডেটা সিংক্রোনাইজেশন।
১৪. **NoSQL adoption:** কিছু রিকোয়েস্টের জন্য NoSQL ব্যবহার।
১৫. **Vertical Partitioning:** কলাম ভিত্তিক টেবিল ভাগ করা।

---

## ২. মেইন কনসেপ্টস

### ক. ইনডেক্সিং (Indexing)

ইনডেক্সিং হলো ডাটাবেসের বইয়ের 'ইনডেক্স' বা সূচিপত্রের মতো। এটি ফুল টেবিল স্ক্যান না করে সরাসরি ডেটা খুঁজে পেতে সাহায্য করে। তবে অতিরিক্ত ইনডেক্সিং রাইট পারফরম্যান্স কমিয়ে দেয়।

### খ. শার্ডিং বনাম পার্টিশনিং (Sharding vs Partitioning)

- **Partitioning:** এটি সাধারণত একটি সিঙ্গেল সার্ভারের মধ্যে কাজ করে। একটি বড় টেবিলকে লজিক্যালি ছোট করা হয় (উদা: বছর অনুযায়ী আলাদা করা)।
- **Sharding:** এটি একটি **Horizontal Scaling** পদ্ধতি। ডেটা ফিজিক্যালি ভিন্ন ভিন্ন সার্ভারে রাখা হয়। এটি অনেক বেশি স্কেলেবল।

### গ. রেপ্লিকেশন (Replication)

ডাটাবেস রেপ্লিকেশনে একটি **Master** সার্ভার থাকে যেখানে রাইট করা হয় এবং অনেকগুলো **Slave/Read Replicas** থাকে যেখান থেকে রিড করা হয়। এটি সিস্টেমের এভেইল্যাবিলিটি বাড়ায়।

### ঘ. ডিনরমালাইজেশন (Denormalization)

রিলেশনাল ডাটাবেসে জয়েন করতে অনেক সময় লাগে। পারফরম্যান্স বাড়াতে আমরা মাঝেমধ্যে ডেটা ডুপ্লিকেট করে রাখি যাতে একটা কুয়েরিতেই সব ডেটা পাওয়া যায়। তবে এতে ডেটা কনসিস্টেন্সি রক্ষা করা কঠিন হয়।

### ঙ. ডেটা কম্প্রেশন (Data Compression)

বড় ডাটাবেসের ক্ষেত্রে স্টোরেজ খরচ কমাতে ডেটা কম্প্রেস করে রাখা হয়। এতে ব্যান্ডউইথ কম লাগে কিন্তু ডেটা রিড/রাইট করার সময় CPU এর ওপর কিছুটা চাপ বাড়ে।

---

## ৩. সিনারিও ভিত্তিক প্রশ্ন (Scenario-based Questions)

### সিনারিও ১: "আপনার রিড রিকোয়েস্ট রাইটের চেয়ে ১০ গুণ বেশি। আপনি কীভাবে স্কেল করবেন?"

**সমাধান:**
১. **Read Replicas:** মাস্টার-স্লেভ আর্কিটেকচার ব্যবহার করব। রিড রিকোয়েস্টগুলো স্লেভ সার্ভারে পাঠিয়ে দেব।
২. **Caching:** Redis বা Memcached ব্যবহার করে ডাটাবেস থেকে রিড কমানোর চেষ্টা করব।

### সিনারিও ২: "একটি টেবিল বড় হতে হতে ১ বিলিয়ন রো হয়ে গেছে। কুয়েরি খুব স্লো হচ্ছে। কী করবেন?"

**সমাধান:**
১. প্রথমে **Indexing** চেক করব।
২. এরপর **Horizontal Partitioning** (Sharding) বা **Vertical Partitioning** করব। টেবিলটি ছোট হলে কুয়েরি ফাস্ট হবে।
৩. যদি পুরনো ডেটা কম লাগে, তবে সেগুলোকে **Cold Storage** বা অন্য কোনো আর্কিভ টেবিল-এ মুভ করব।

### সিনারিও ৩: "শার্ডিং করার সময় কীভাবে ডেটা ডিস্ট্রিবিউশন করবেন যাতে কোনো একটি সার্ভারে বেশি চাপ না পড়ে?"

**সমাধান:**
এখানে **Consistent Hashing** ব্যবহার করা উত্তম। এটি নিশ্চিত করবে যে সার্ভার বা শার্ড যুক্ত বা রিমুভ করলেও ডেটা ডিস্ট্রিবিউশন ব্যালেন্সড থাকে এবং 'Hot Shard' হওয়ার সম্ভাবনা কমে।

---

> [!IMPORTANT]
> ডাটাবেস স্কেলিং করার আগে সবসময় **Query Optimization** এবং **Indexing** দিয়ে চেষ্টা করা উচিত। এগুলো কাজ না করলে তখন শার্ডিং বা রেপ্লিকেশনের মতো জটিল এবং ব্যয়বহুল পদ্ধতিতে যাওয়া উচিত।
